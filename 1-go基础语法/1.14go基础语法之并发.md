# 并发与并行

**Golang语言层面即支持并发**

**并发：同一个时间段内执行多个任务（“单核心情况下“，在同一个时间段，在多个任务之间切换，从宏观一段时间上来看，就像是这些任务在同时进行；但是！同一个时间点，只能执行一个任务**

**并行：同一个时刻执行多个任务（需要有多个处理“核心”，每个处理核心都处理任务，可以在同一个时刻/时间点，同时进行**

Golang的并发通过goroutine实现，goroutine类似线程，属于用户态的线程，根据需要，可以创建成千上万个goroutine进行并发工作，goroutine是由go语言的运行时runtime调度完成，而线程是由操作系统调度完成

go提供了channel在多个goroutine间进行通信，goroutine和channel是go秉承的CSP（communication sequential process）并发模式的重要实现基础

# goroutine

java/c++中，我们需要实现并发的时候，通常需要自己维护一个线程池，并且需要自己去包装一个又一个的任务，同时需自己去调度线程执行任务并维护上下文切换，比较耗费心智，而**golang提供了一种机制：程序员只需要定义很多个任务，让go的运行时去帮助程序员把这些任务分配到cpu上实现并发执行，即go的goroutine。**

goroutine的概念类似于线程，但goroutine是由go的运行时runtime调度和管理的，go程序会智能地把goroutine中任务合理分配给每个cpu。

**go在语言层面，内置了调度和上下文切换**

go编程中，你不需要去自己写进程、线程、协程，当需要让某个任务并发执行的时候，只需要把任务包装成一个函数，加个go关键字，开启一个goroutine去执行这个函数就行了。

## 使用goroutine

go语言中，使用goroutine非常简单，只需要在调用函数的时候在前面加上go关键字，就可以为一个函数创建一个goroutine

一个goroutine必定对应一个函数，可以创建多个goroutine去执行相同的函数

## 启动单个goroutine

启动goroutine，只需要在调用的函数（普通函数和匿名函数）前面加上一个go关键字

e.g.

下例中，hello（）函数和下方的打印是串行，

```go
package main

import "fmt"

func hello() {
	fmt.Println("this is hello func")
}

func main() {
	hello()
	fmt.Println("this is main func")
}


latteplus@LAPTOP-00EFC09V MINGW64 /d/myCode/Go/src/learngo/basic_grammar/18goroutine (master)
$ go run main.go
this is hello func
this is main func
```

**利用goroutine启动函数**

在调用hello()函数前，加一个go就可以了，但是输出中只输出了一句this is main func 没有输出hello函数中的内容，**原因是启动一个goroutine会耗费一点时间，但此时代码会继续向下执行，打印下方的内容，之后main函数就会退出，main含数一退出，其内部启动的所有goroutine都会被停掉，**

```go
package main

import "fmt"

func hello() {
	fmt.Println("this is hello func")
}

func main() {
	go hello()
	fmt.Println("this is main func")
}
$ go run main.go
this is main func
```

**解决方法：打印后sleep个几秒，给goroutine内部的函数有充足的时间执行**

可以看到，先打印了main，才打印了hello，（因为启动goroutine去执行hello需要一定时间

```go
package main

import (
	"fmt"
	"time"
)

func hello() {
	fmt.Println("this is hello func")
}

func main() {
	go hello()
	fmt.Println("this is main func")
	time.Sleep(time.Second)
}
$  go run main.go
this is main func
this is hello func
```



## 启动多个goroutine

发现，每次执行结果不一样，因为多个goroutine并发执行，每次的调度顺序都一定完全一样，所以打印10个数字的顺序几乎每次不同

```go
package main

import (
	"fmt"
	"sync"
)

var wg sync.WaitGroup

func hello(a int) {
	// 注册一个操作，函数退出前，记得关闭goroutine，wg.Add加了几个，往往就需要关闭几个
	defer wg.Done()
	fmt.Println(a)
}

func main() {

	for i := 0; i < 10; i++ {
		// 每循环一次启动一个goroutine
		// 启动goroutine前，先注册，利用wg.Add()方法
		wg.Add(1)
		go hello(i)

	}

	// 等待所有goroutine结束，每wg.Done()一次，就会把wg.Add()减1，直到减到0，此时代表所有goroutine都完成工作，若下方还有代码，才可以继续执行
	wg.Wait()
    fmt.Println("10 goroutine done!")
}

latteplus@LAPTOP-00EFC09V MINGW64 /d/myCode/Go/src/learngo/basic_grammar/18goroutine (master)
$  go run main.go
9
5
7
4
0
1
2
3
6
8
10 goroutine done!
latteplus@LAPTOP-00EFC09V MINGW64 /d/myCode/Go/src/learngo/basic_grammar/18goroutine (master)
$  go run main.go
9
0
3
1
2
4
6
7
8
5
10 goroutine done!
```



# goroutine与线程

## 可增长的栈

os的线程即操作系统的线程，一般都有固定的栈内存（通常是2MB，**而一个goroutine线程在其生命周期开始时，其栈大小通常只有2KB，**而且其栈大小可以根据需要动态的调整，其最大栈大小可以达到1GB，（因此go中一次型创建10万左右的goroutine也是可以的



## goroutine调度

goroutine是go运行时管理的用户态的线程，其本质还是要靠os的线程来实际运行，一个os线程对应多个用户态的goroutine，goroutine之间的调度切换，是在用户态完成，不需要用户态和内核态之间切换，（因此较为轻量）

**GPM就是实现goroutine调度的系统：**

- G就是值goroutine，里面存放了goroutine本身的信息，还有所在绑定P的信息
- P管理着一组goroutine，P里面会存储当前goroutine的上下文信息（函数指针、堆栈地址、地址边界）P会对自己管理的goroutine进行调度（比如将占用cpu时间长的goroutine暂停，运行后续的goroutine）当自己队列消费完了就去全局队列取，如果全局队列消费完了就是其他P的队列里抢任务
- M（machine）是go运行时对操作系统内核线程的虚拟，M和内核线程一般是一一对应的关系，**一个goroutine最终要放到M上执行的**

**P和M一般也是一一对应**，关系是：P管理着一组G，挂到一个M上，这组G都由这个M实际来负责运行，（即由这个M对应的cpu核心来执行？）当某个G阻塞到了M上，P就会新建一个M，并其组内其他G迁移到新的M上，而等到阻塞的G完成或者认为完成不了把它退出时，回收旧的M

P的个数是通过`runtime.GOMAXPROCS`设定，最大是256，go1.5版本后默认是物理线程数，并发量大的时候可以适当增加一些P和M，但加太多就得不偿失，因为底层就这么多cpu核心，加多了还不是得让cpu核心做上下文切换，反而拖慢了

单从线程调度来讲，go相比其他语言的优势是在于os线程是有内核调度，而go的goroutine是由go运行时调度，**调度器采用m:n调度，即把m的goroutine调度到n个os线程上，**全部在用户态，上下文切换的成本小，**不涉及内核态用户态的频繁切换，内存池由用户态维护，几乎是平均的把若干goroutine调度到多个cpu核心，充分利用了多核cpu硬件优势

**如下图示：**

（不一定对，先这么理解

![image-20210131093815623](https://gitee.com/boogie96/pic-go-bed/raw/master/img/image-20210131093815623.png)

[拓展阅读](https://www.cnblogs.com/sunsky303/p/9705727.html)



## GOMAXPROCS

go运行时可以通过GOMAXPROCS参数设定启用多少个os线程来运行go代码，默认值是机器的cpu核心数，例如一个8核心服务器，默认就是启用8个os线程，（m：n中的n是8）

通过runtime.GOMAXPROCE()函数可以设置当前程序并发时占用了cpu核心数

go1.5之前，默认用单核心，go1.5之后，默认使用全部的逻辑核心数

例1：2个goroutine只用一个核心

可以看到，先执行完b的goroutine之后，再执行的a的goroutine，（虽然一个核心，但也应该交叉调度运行，但因为10比较小，几乎不用调度，先执行一个，再执行后一个，实验中，10加到10000时，即便是单核心，也会交叉运行输出）

```go
package main

import (
	"fmt"
	"runtime"
	"time"
)

func a() {
	for i := 0; i < 10; i++ {
		fmt.Printf("this is func a %d\n", i)
	}

}

func b() {
	for i := 0; i < 10; i++ {
		fmt.Printf("this is func b %d\n", i)
	}

}

func main() {
	runtime.GOMAXPROCS(1)
	go a()
	go b()
	time.Sleep(time.Second * 2)

}

latteplus@LAPTOP-00EFC09V MINGW64 /d/myCode/Go/src/learngo/basic_grammar/18goroutine (master)
$ go run main.go
this is func b 0
this is func b 1
this is func b 2
this is func b 3
this is func b 4
this is func b 5
this is func b 6
this is func b 7
this is func b 8
this is func b 9
this is func a 0
this is func a 1
this is func a 2
this is func a 3
this is func a 4
this is func a 5
this is func a 6
this is func a 7
this is func a 8
this is func a 9
```



例2: 2个goroutine用2个核心

可以看到，虽然10比较小，但是仍然是交叉输出，因为有2个核，可以同时跑a和b的goroutine

```go
package main

import (
	"fmt"
	"runtime"
	"time"
)

func a() {
	for i := 0; i < 10; i++ {
		fmt.Printf("this is func a %d\n", i)
	}

}

func b() {
	for i := 0; i < 10; i++ {
		fmt.Printf("this is func b %d\n", i)
	}

}

func main() {
	runtime.GOMAXPROCS(2)
	go a()
	go b()
	time.Sleep(time.Second * 2)

}

latteplus@LAPTOP-00EFC09V MINGW64 /d/myCode/Go/src/learngo/basic_grammar/18goroutine (master)
$ go run main.go
this is func b 0
this is func b 1
this is func b 2
this is func a 0
this is func a 1
this is func a 2
this is func a 3
this is func a 4
this is func a 5
this is func a 6
this is func a 7
this is func a 8
this is func a 9
this is func b 3
this is func b 4
this is func b 5
this is func b 6
this is func b 7
this is func b 8
this is func b 9
```

**操作系统线程和goroutine的关系**

- goroutine和os线程是m：n的关系
- go程序可以同时刻，使用多个os线程，即多个cpu核心
- 一个os线程，对应多个用户态的goroutine

# channel

单纯的将函数并发执行并无意义，函数与函数之间，还需要进行通信，即数据交换，**go中利用channel实现并发函数之间的通信**

实现进程间通信的方法可以通过共享内存实现，**但是共享内存去通信，多个进程同时访问同一块内存的时候，会出现竞争，这时需要加锁，这就造成了性能上的低下，**

**而go中，提倡通过通信而共享内存，而不是通过共享内存实现通信：通过CSP（communicating sequential process)并发模型实现，通过channel，实现一个goroutine向另一个goroutine发送数据，channel就像是一个管道或者传递带，你在这头发，我在那头取**

channel遵从先进先出的规则，里面可以存储各种类型的数据

## channel类型

**channel的类型决定了它能传输什么样的数据**

channel是一种类型，一种引用类型，声明格式：

```go
var 变量名 chan 元素类型

// 例子
var ch1 chan int
var ch2 chan string
var ch3 chan []int

// 上面3个通道变量，分别用于传输 int string []int类型的数据
```





## 创建channel

channel是引用类型，所以其空值是nil

```go
package main

import "fmt"

func main() {
	var ch1 chan int
	fmt.Println(ch1) // 是nil
}

$ go run main.go
<nil>
```

只声明不行，还得用make初始化后才能使用

```go
// 语法： make(chan 通道内存放的数据类型 , [通道的缓冲区大小,可选])
	ch2 := make(chan int, 10)
	ch3 := make(chan string)
	ch4 := make(chan bool, 9)
```



## channel操作

**channel具有发送、接收、关闭三种操作，发送接收都用`<-`**表示

**先定义一个通道**

```go
ch := make(chan int)
```



**发送**

```go
ch <- 10 // 发送一个10
```

**接收**

```go
x := <- ch // 从ch中接收一个值，并赋值给x
<- ch // 从ch中接收一个值，并丢弃，即忽略
```

**关闭**

关闭通道就是相当于把通道的入口关闭了，但是出口没关

```go
close(ch) // 调用内置的close方法，关闭即可
```

**和文件操作不同的是，文件打开后必须关闭，而通道则不是必须关闭，其可以被垃圾回收机制回收**

**已经关闭通道的特点**

1. 入口关闭了，再向该通道内传值会引发panic
2. 出口没关闭，可以从该通道内继续接收值，直到通道内数据被取完，即通道变空
3. 从一个关闭的通道，且已经取完了数据的通道，继续接收值，不会panic，只是会收到对应类型的零值
4. 已经关闭的通道，再关闭一次，会引发panic

## 无缓冲的通道

**无缓冲的通道，又称为阻塞的通道**

例子：编译能通过，但是运行会爆出死锁

```go
package main

func main() {
	ch1 := make(chan int)

	ch1 <- 10
}

$ ./19channel.exe
fatal error: all goroutines are asleep - deadlock!

goroutine 1 [chan send]:
main.main()
        D:/myCode/Go/src/learngo/basic_grammar/19channel/main.go:6 +0x57
```

上例的原因是：没有缓冲区的通道，发送值的时候，必须有一方在通道另一边接着，不然发送方就一直等，直到卡死，爆出死锁（好比小区没有快递柜，快递员送快递时，必须等你到了，把快递交到你手上）

解决上例子的问题：

```go
// 启用一个goroutine来从通道收值
package main

import (
	"fmt"
	"time"
)

func recv(c chan int) {
	ret := <-c
	fmt.Printf("接收成功：%d\n", ret)
}
func main() {
	ch1 := make(chan int)
	// 先启动一个goroutine，准备从ch1通道接收值，此时goroutine会等待一会，直到下面一行，向ch1中发送一个值，此时2个goroutine都可以正常通过执行
	go recv(ch1)
	ch1 <- 10
    // 要等一会，不然会来不及打印，接收成功这句，就退出了
	time.Sleep(time.Second)
	// fmt.Println("发送成功")
}

```

**使用无缓冲的通道进行通信，会使得通道2端的发送goroutine和接收goroutine同步化，因此无缓冲通道又被称为同步通道**



## 有缓冲的通道

有缓冲的通道，就是初始化时，给通道申请至少一个单位的空间，

有缓冲的通道也会阻塞，即通道中空间放满了数据，还没被取走，此时再放值就会阻塞

```go
package main

import "fmt"

func main() {
	ch1 := make(chan int, 1)
	ch1 <- 10
	fmt.Println(len(ch1))
	ret := <-ch1
	fmt.Println(ret)
	fmt.Println(len(ch1))
	fmt.Println(cap(ch1))
}
$ go run main.go
1
10
0
1
```

len可以获取通道内元素的数量，cap可以获取通道的总容量

## for range从通道循环取值

for range 从通道遍历值的时候，当遍历的通道关闭，就会自动退出for range

```go
package main

import "fmt"

func main() {
	// 声明2个无缓冲的通道
	ch1 := make(chan int)
	ch2 := make(chan int)

	// 开一个goroutine 一个匿名函数，作为立即执行函数，向ch1中放入1到10的值
	go func() {
		for i := 0; i <= 10; i++ {
			ch1 <- i
		}
		close(ch1)
	}()

	// 开一个goroutine 一个匿名函数，作为立即执行函数，从ch1中取出值，计算平方后，放入ch2
	go func() {
		for i := 0; i <= 10; i++ {
			ret, ok := <-ch1 // 当ch1关闭，再取值，返回的ok就是false
			if !ok {
				break
			}
			ch2 <- ret * ret
		}
		close(ch2)

	}()
	// 主函数的goroutine，从ch2中遍历取出值，并打印
    // 因为ch1和ch2都是无缓存的通道，close(ch2)能执行的条件就是，10个数的平方，都被放到ch2中，并随即被主goroutine打印出来，
    // 即无缓冲通道使得，这三个goroutine是同步的，ch1放一个，取出一个计算平方放到ch2，随即被打印，然后开始下一次循环
	for x := range ch2 {
		fmt.Println(x)
	}
}

```



## 单向通道

在函数中，经常需要将一个通道，作为传参，在多个功能函数内部使用，**为了安全考虑，可以定义将一个通道传递到一个函数中时，限制该函数内部可以对该通道执行的操作，**可以将通道定义为单向通道，即函数内部只能对这个通道进行只发或只收操作

改造上面的例子

```go
package main

import "fmt"

func send(ch chan<- int) {
	for i := 0; i < 10; i++ {
		ch <- i
	}
	close(ch)

}
func squarer(chSend chan<- int, chRecv <-chan int) {
	// 从chRecv取值，计算平方后，放入chSend

	for tmp := range chRecv {
		chSend <- tmp * tmp
	}
	close(chSend)
}

func print(ch <-chan int) {
	for x := range ch {
		fmt.Println(x)
	}
}
func main() {
	ch1 := make(chan int)
	ch2 := make(chan int)
	go send(ch1)
	go squarer(ch2, ch1)
	print(ch2)
}
$ ./19channel.exe
0
1
4
9
16
25
36
49
64
81
```

- <-chan 只能从里读数据
- chan<- 只能向里写数据

函数传参的时候，双向通道可以改成单向通道，反之不可以

## 通道总结

![image-20210131140213685](https://gitee.com/boogie96/pic-go-bed/raw/master/img/image-20210131140213685.png)

**关闭一个已经关闭的通道会panic**

# worker pool(goroutine池)

工作中，常常利用worker  pool模式，即goroutine池，来限制goroutine的数量，防止goroutine的暴涨或泄漏

e.g.

```go
package main

import (
	"fmt"
	"sync"
	"time"
)

// worker pool
var wg sync.WaitGroup

func worker(id int, ch1 <-chan int, ch2 chan<- int) {
	defer wg.Done()
	for j := range ch1 {
		fmt.Printf("worker:%d, do job:%d\n", id, j)
		// time.Sleep(time.Second)，这句放在前面，会导致放入ch2的数据不是1-5这个顺序，放到下面就是
		ch2 <- j * 2
        time.Sleep(time.Second)
	}
}

func main() {
	jobs := make(chan int, 10)
	results := make(chan int, 10)
	// 启动3个goroutine
	for i := 1; i <= 3; i++ {
		wg.Add(1)
		go worker(i, jobs, results)
	}

	// 向任务队列中，放入5个任务
	for i := 1; i <= 5; i++ {
		jobs <- i
	}
	close(jobs)

	wg.Wait()
	// for x := range results {
	// 	fmt.Println(x)
	// }
	for i := 1; i <= 5; i++ {
		res := <-results
		fmt.Println(res)
	}

}
// 运行结果：3个worker即3个goroutine分5个任务，本次运行中1和3各自执行了2个任务，2执行了1个任务
$ go run main.go
worker:3, do job:1
worker:1, do job:2
worker:2, do job:3
worker:1, do job:4
worker:3, do job:5
4
2
6
10
8
$ go run main.go
worker:3, do job:1
worker:1, do job:2
worker:2, do job:3
worker:3, do job:4
worker:2, do job:5
2
4
6
8
10
```



# select多路复用

当通道中没有值的时候，从通道中接收值会一直阻塞，直到通道中再次有值，对于同时从多个通道接收值的情况，可以采用如下循环：通过判断ok的值，确定是否继续接收

```go
for {
    v , ok := <- ch1
    	...
    v , ok := <- ch2
}
```

**但上述方式，性能较差，因此go提供了select关键字，可以同时响应多个通道的操作，收或发都可以**

**select类似于switch操作，有一系列case分支和一个默认分支：每个case分支都有对应一个通道的操作，收或发，当某个case分支的通道的收或发的操作满足时，就会执行该case下的语句，当多个case同时满足时，就随机选择一个case执行**

语法：

```go
select {
case <-ch1:
	...
case ch2<- data:
	...
case data := <-ch2:
	...
default
	默认操作
}    
```



e.g.

```go
package main

import (
	"fmt"
)

func main() {

	ch1 := make(chan int, 1)

	for i := 0; i < 10; i++ {
		select {
		case x := <-ch1:
			fmt.Println(x)
		case ch1 <- i:

		}
	}
}
$ go run main.go
0
2
4
6
8
```

select语句可以挺高代码的可读性

- 可以处理一个或多个channel的发送或接收操作
- 多个case同时满足，会随机选择一个
- 没有case的select{}会一直等待，可用于阻塞main函数



# 并发安全和锁

多个goroutine执行同一个函数，而函数中又涉及到了一个函数外部的变量，此时由于goroutine是并发执行，当多个goroutine操作同一个变量时，就一般会发生**数据竞争**，造成结果的不确定性

下例中，

```go
package main

import (
	"fmt"
	"sync"
)

var x int64
var wg sync.WaitGroup

func add() {
	defer wg.Done()
	for i := 0; i < 50000; i++ {
		x = x + 1
	}
	// 正常情况下，这个函数只有一个goroutine在执行时，x最后应该是50000
    // 而没有加锁的情况下，因为是2个goroutine同时操作一个外部变量x，一个goroutine操作数据+1时，另一个goroutine可能已经把x加了1，所以最终结果一般都大于50000，但为啥，加不到100000呢？
}
func main() {
	// wg.Add(1)
	wg.Add(2)
	go add()
	go add()
	wg.Wait()

	fmt.Println(x)
}

$ go run main.go
71142

latteplus@LAPTOP-00EFC09V MINGW64 /d/myCode/Go/src/learngo/basic_grammar/19channel (master)
$ go run main.go
51122

latteplus@LAPTOP-00EFC09V MINGW64 /d/myCode/Go/src/learngo/basic_grammar/19channel (master)
$ go run main.go
52482

latteplus@LAPTOP-00EFC09V MINGW64 /d/myCode/Go/src/learngo/basic_grammar/19channel (master)
$ go run main.go
52701

```

## 互斥锁

互斥锁，又叫读写互斥锁，**用sync的Mutex表示**，当多个goroutine操作同一个变量时，需要先申请一个锁，然后才可以对数据进行操作，操作期间，其他goroutine不能读，也不能写，只有这个goroutine完事了，释放锁，其他goroutine才能申请锁，然后对变量进行操作，（多个goroutine同时等待一个锁的时候，被唤醒是随机选择的

**好比，你上公共厕所，锁上门后，别人不能跟你一起上（写），也不能看着你上（读）有画面了:laughing:**

用锁，修正上面的代码

```go
package main

import (
	"fmt"
	"sync"
)

var wg sync.WaitGroup
var x int // 默认是0

// 声明一个互斥锁
var lock sync.Mutex

func add() {
	defer wg.Done()
	for i := 0; i < 50000; i++ {
		lock.Lock() // 加锁
		x = x + 1
		lock.Unlock() // 解锁
	}

}

func main() {
	wg.Add(2)
	go add()
	go add()
	wg.Wait()

	fmt.Println(x)
}

```



## 读写互斥锁

**互斥锁是读写完全互斥的，即即使不修改数据，并发的读也不能实现，需得一个个申请锁；但是：很多场景，都是读多写少，因此互斥锁会拖慢效率，因此引入读写互斥锁**

**读写互斥锁分2种，读锁，申请读锁时，后续其他人也可以申请读锁，继续读，但某人有个写锁后，其他后续的读或写都得等待（因为写期间导致数据修改，这时读会读到不确定的数据**

示例：

```go
package main

import (
	"fmt"
	"sync"
	"time"
)

var wg sync.WaitGroup
var x int // 默认是0

var lock sync.Mutex
var rwlock sync.RWMutex

func read() {
	defer wg.Done()

	// lock.Lock()
	rwlock.RLock()               // 加读锁
	time.Sleep(time.Microsecond) // 模拟读耗费1毫秒
	rwlock.RUnlock()             // 释放读锁
	// lock.Unlock()

}

func write() {
	defer wg.Done()

	// lock.Lock()
	rwlock.Lock() // 加写锁
	x = x + 1
	time.Sleep(time.Microsecond * 3) // 模拟写话费3毫秒
	rwlock.Unlock()                  // 释放写锁
	// lock.Unlock()
}

func main() {
	start := time.Now()
	for i := 0; i < 1000; i++ {
		wg.Add(1)
		go read()
	}

	for i := 0; i < 10; i++ {
		wg.Add(1)
		go write()
	}
	wg.Wait()
	end := time.Now()
	fmt.Println(x)
	fmt.Println("读写互斥锁花费时间:", end.Sub(start))
	// fmt.Println("互斥锁花费时间:", end.Sub(start))
}
$ go run main.go
10
读写互斥锁花费时间: 16.0008ms

$ go run main.go
10
互斥锁花费时间: 1.0430442s
```

可以看到，互斥锁花的时间比读写互斥锁要多很多，读写比，越大，效果越明显，读写比相近时，差别不大；

## sync.WaitGroup

sync.WaitGroup可以确定多个并发任务结束的时间，而不是用sleep，因为你无法准确预估并发goroutine结束时间，

使用步骤：

1. var wg sync.WaitGroup 实例化一个sync.WaitGroup
2. 每启动一个goroutine之前，就wg.Add(1) 表示注册一个goroutine，计数器加一
3. 每个goroutine要执行的函数，都加一个defer wg.Done()表示结束该goroutine，计数器减一
4. wg.Wait()等到计数器减为0，才继续向下执行，减为0前代码为阻塞状态

sync.WaitGroup具有的方法

| 方法名                              | 作用              |
| ----------------------------------- | ----------------- |
| func (wg *WaitGroup) Add(delta int) | 计数器加delta     |
| func (wg *WaitGroup) Done()         | 计数器减一        |
| func (wg *WaitGroup) Wait()         | 阻塞直到计数器归0 |



```go
type WaitGroup struct {
	noCopy noCopy

	// 64-bit value: high 32 bits are counter, low 32 bits are waiter count.
	// 64-bit atomic operations require 64-bit alignment, but 32-bit
	// compilers do not ensure it. So we allocate 12 bytes and then use
	// the aligned 8 bytes in them as state, and the other 4 as storage
	// for the sema.
	state1 [3]uint32
}
是个结构体，
```



## sync.Once

启动多个goroutine执行同一个函数时，因为同一个函数，代码块相同，若其中存在加载文件、关闭文件、关闭通道，这些语句，那么在并发执行这个函数时，就是并发不安全的，因为“通道只能关闭一次”这些原因

于是go提供了sync.Once使得这些函数并发执行时，这些代码只执行一次

sync.Once只有一个方法

```go
func (o *Once) Do(f func()) {
    
}
// 参数是无传参，无返回值的函数，若需要传递参数，则可以利用闭包实现
```

**并发安全的单例模式**

```go
package singleton

import "sync"

type singleton struct {}

var instance *singleton
var once sync.Once

func GetInstance() *singleton {
    once.Do(func() {
        instance = &singleton{}
    })
    return instance
}
```

sync.Once内部包含一个互斥锁和一个布尔值，布尔值用于记录是否被执行过一次

## sync.Map

go内置的map不是并发安全的，

看下例

```go
package main

import (
	"fmt"
	"strconv"
	"sync"
)

var wg sync.WaitGroup
var m = make(map[string]int)

func get(key string) int {
	return m[key]
}

func set(k string, v int) {
	m[k] = v
}

func main() {

	for i := 0; i < 1; i++ {
		wg.Add(1)
		go func(n int) {
			// 先将n转成字符串
			str := strconv.Itoa(n)
			set(str, n)
			fmt.Printf("key: %s , value: %d", str, get(str))
			wg.Done()
		}(i) // 启动20个并发执行的，立即执行匿名函数
	}
	wg.Wait()
}

// 当只有一个goroutine时，不会出错
$ go run main.go
key: 0 , value: 0

// 当大于等于2个goroutine时，就会报错，fatal error: concurrent map writes，因为内置map就是并发不安全的

$ go run main.go
fatal error: concurrent map writes
key: 0 , value: 0
```

**内置的sync.Map**

原生支持并发的map，并不需要make初始化，声明即用，且内置了Store Load LoadOrStore Delete Range等方法

```go
package main

import (
	"fmt"
	"strconv"
	"sync"
)

var wg sync.WaitGroup
var m = sync.Map{} // 声明

func main() {

	for i := 0; i < 10; i++ {
		wg.Add(1)
		go func(n int) {
			// 先将n转成字符串
			str := strconv.Itoa(n)
			m.Store(str, n)
			value, _ := m.Load(str)
			fmt.Printf("key: %s , value: %d\n", str, value)
			wg.Done()
		}(i) // 启动20个并发执行的，立即执行匿名函数
	}
	wg.Wait()
}

```



# 原子操作

**加锁操作，涉及了内核态和用户态的切换，消耗较高，因此针对基本数据类型go提供了原子操作保证并发安全，且是在用户态完成，性能比加锁更好，**

由sync/atomic提供

## atomic包

![image-20210201164247064](https://gitee.com/boogie96/pic-go-bed/raw/master/img/image-20210201164247064.png)

## 示例

比较互斥锁和原子操作的性能

1. 不加锁，并发不安全
2. 用互斥锁实现并发安全，性能较低
3. 用原子操作实现并发安全，性能较高（并发数量较大时，

```go
package main

import (
	"fmt"
	"sync"
	"sync/atomic"
	"time"
)

type Counter interface {
	Inc()
	Load() int64
}

// 普通版
type CommonCounter struct {
	counter int64
}

func (c CommonCounter) Inc() {
	c.counter++
}

func (c CommonCounter) Load() int64 {
	return c.counter
}

// 互斥锁版
type MutexCounter struct {
	counter int64
	lock    sync.Mutex
}

func (m *MutexCounter) Inc() {
	m.lock.Lock()
	defer m.lock.Unlock()
	m.counter++
}

func (m *MutexCounter) Load() int64 {
	m.lock.Lock()
	defer m.lock.Unlock()
	return m.counter
}

// 原子操作版
type AtomicCounter struct {
	counter int64
}

func (a *AtomicCounter) Inc() {
	atomic.AddInt64(&a.counter, 1)
}

func (a *AtomicCounter) Load() int64 {
	return atomic.LoadInt64(&a.counter)
}

func test(c Counter) {
	var wg sync.WaitGroup
	start := time.Now()
	for i := 0; i < 10000000; i++ {
		wg.Add(1)
		go func() {
			c.Inc()
			wg.Done()
		}()
	}
	wg.Wait()
	end := time.Now()
	fmt.Println(c.Load(), end.Sub(start))
}

func main() {
	c1 := CommonCounter{} // 非并发安全
	test(c1)
	c2 := MutexCounter{} // 使用互斥锁实现并发安全
	test(&c2)
	c3 := AtomicCounter{} // 原子锁，实现并发安全且比互斥锁效率更高
	test(&c3)
}

// 开启的gourtine不够大时，原子操作，反而比互斥锁慢
ten@DESKTOP-7ICOPRG MINGW64 /c/myworkstation/mygocode/src/learngo/basic_grammar/19channel (master)
$ go run main.go
0 15.0003ms
10000 12.0007ms
10000 16.0012ms

ten@DESKTOP-7ICOPRG MINGW64 /c/myworkstation/mygocode/src/learngo/basic_grammar/19channel (master)
$ go run main.go
0 113.0053ms
100000 133.0061ms
100000 127.0134ms

ten@DESKTOP-7ICOPRG MINGW64 /c/myworkstation/mygocode/src/learngo/basic_grammar/19channel (master)
$ go run main.go
0 8.9425007s
10000000 15.072139s
10000000 10.4685442s
```



# 练习题


1. 使用goroutine和channel实现一个计算int64随机数各位数和的程序。
	1. 开启一个goroutine循环生成int64类型的随机数，发送到jobChan
	2. 开启24个goroutine从jobChan中取出随机数计算各位数的和，将结果发送到resultChan
	3. 主goroutine从resultChan取出结果并打印到终端输出
2. 为了保证业务代码的执行性能将之前写的日志库改写为异步记录日志方式。

## 练习1

使用goroutine和channel实现一个计算int64随机数各位数和的程序。

1. 开启一个goroutine循环生成int64类型的随机数，发送到jobChan
2. 开启24个goroutine从jobChan中取出随机数计算各位数的和，将结果发送到resultChan
3. 主goroutine从resultChan取出结果并打印到终端输出

```go
package main

import (
	"fmt"
	"math/rand"
	"sync"
)

/*
1,定义2个channel ：jobChan和resChan
2，produceJob 函数，利用rand生成int64位的随机数，放到jobChan（开启1个goroutine执行
3，customJob  函数，从jobChan中接收数据，利用取余法，获得各个位数的值，相加后放到resChan中（开通24个goroutine执行
4，利用wg.Wait()等待2个goroutine全部完成后，从resChan中便利结果打印即可

*/
// 声明2个jobChan

var wg sync.WaitGroup

// produceJob 生成10个随机数，并到jobChan中
func produceJob(job chan<- int64) {
	defer wg.Done()
	for i := 0; i < 100; i++ {

		randNum := rand.Int63()
		fmt.Printf("%d, %d\n", i, randNum)

		job <- randNum
	}
	close(job)
}

func customJob(job <-chan int64, res chan<- int) {
	defer wg.Done()

	sum := 0
	num := <-job
	for num > 0 {
		sum = int(num%10) + sum
		num = num / 10
	}
	res <- sum

}
func main() {

	var jobChan = make(chan int64, 100)
	var resChan = make(chan int, 100)
	wg.Add(1)
	go produceJob(jobChan)
	for i := 0; i < 100; i++ {
		wg.Add(1)
		go customJob(jobChan, resChan)
	}
	wg.Wait()

	for a := 0; a < 100; a++ {
		fmt.Printf("%d, %d\n", a, <-resChan)
	}

}

前10个结果：
$ go run main.go
0, 5577006791947779410
1, 8674665223082153551
2, 6129484611666145821
3, 4037200794235010051
4, 3916589616287113937
5, 6334824724549167320
6, 605394647632969758
7, 1443635317331776148
8, 894385949183117216
9, 2775422040480279449

0, 95
1, 79
2, 81
3, 53
4, 95
5, 80
6, 99
7, 77
8, 89
9, 80
```



## 练习2

为了保证业务代码的执行性能将之前写的日志库改写为异步记录日志方式。

```go
package mylogger

import (
	"fmt"
	"os"
	"path/filepath"
	"time"
)

/*

该file.go文件需要实现的代码

1. filelogger结构体
	包含：
	日志文件路径
	文件名
	文件切割时的大小，即日志文件最大能达到的大小
	日志级别LogLevel类型
	一个普通日志文件对象
	一个错误日志文件对象，（单独记录一份错误日志）

	（文件名包含2个，一个记录所有日志，一个记录error级别以上的错误日志）

2. filelogger结构体的构造函数
	返回fileLogger的指针类型


3. 6个日志级别的记录方法，接受者是指针类型的filelogger

4. log函数
	负责实现记录日志的函数，由上面6个日志级别的记录方法调用

5. isEnable函数，判断是否记录该级别的日志，由负责实际记录日志的函数调用

6. checkSize函数
	记录日志时，根据当前日志文件的大小，判断是否需要进行日志文件的轮替，即日志切割

7. splitFile函数
	若经过了checkSize函数的检查，需要进行日志切割的时候，则调用split函数进行日志文件的切割

8. initFile函数
	被filelogger的构造函数调用，进行日志文件的初始打开工作，得到普通日志文件，错误日志文件的2个文件对象，从而得到一个完整的filelogger实例

9. 总结一下，该文件的代码逻辑：
	其他代码先import该库；
	通过fileLogger的构造函数，传入需要的参数，假设传入的日志级别为INFO，
		再调用initFile函数，得到2个文件对象
		得到一个filelogger的实例，如f1
	需要记录某级别的一条日志时，就调用该实例的对于级别方法，如f1.WARNING
	进入到INFO方法内部：
		直接将参数传给log，调用log函数，进入log函数内部：
			先调用isEnable函数，判断是否记录该级别日志，warning大于info，进行记录；
				然后记录前，调用checkSize函数：
					判断当前日志文件大小是否超出了定义了日志文件最大值
						大于，就调用splitFile函数，进行日志切割
						小于，就直接进行日志记录
			然后，判断该级别是不是大于等于ERROR级别
				大于，则单独记录一份日志到错误日志文件
					先checkSize判断错误日志文件的大小，
						超过最大值就调用split进行文件切割
						不超过，就直接进行日志记录
			不是，则不进行任务记录
	至此，完成了一条日志的记录

*/

/*
利用goroutine和channel改写，实现异步方式写日志
思路：
0，构造一个通道，构造一个日志消息的结构体，通道的类型是这个日志消息结构体的指针类型
1，何时开启，日志写入通道的goroutine
	调用DEBUG TRACE INFO ...这6个记录不同级别日志的方法时，其实是调用了f.recordLog(DEBUG, format, args...)，这个函数去记录日志，（原来的方式是同步写日志，一条日志的记录会走遍所有的函数，效率较低）
	改造f.recordLog函数，在这个函数内部，把要写的日志信息放到日志通道中；
2，何时开启，日志消费goroutine
	在初始化一个FileLogger实例的时候，就开启一个goroutine，新增一个日志消费函数，writeLogBackGround放在这个goroutine中执行

*/
// FileLogger ...
type FileLogger struct {
	level       LogLevel
	filedir     string
	filename    string
	errfilename string
	maxsize     int64
	fileObj     *os.File
	errfileObj  *os.File
	logmsg      chan *logInfo // 新加一个 通道，通道类型是存放logInfo结构体的指针
}

// 改造：新加一个日志消息结构体
type logInfo struct {
	now      string
	loglevel LogLevel
	funName  string
	fileName string
	lineNo   int
	msg      string
	// now, loglevel, funName, fileName, lineNo, msg
}

// NewFileLogger 构造一个FileLogger实例
func NewFileLogger(lv string, filedir string, filename, errfilename string, maxsize int64) *FileLogger {
	loglevel, err := parseLogLevel(lv)
	if err != nil {
		panic(err)
	}

	f := &FileLogger{
		level:       loglevel,
		filedir:     filedir,
		filename:    filename,
		errfilename: errfilename,
		maxsize:     maxsize,
		logmsg:      make(chan *logInfo, 5000), // 实例化FileLogger时，就申请开辟一个5000大小的通道
	}
	// fileObj, err := f.initFile(filedir, filename)
	// errfileObj, err := f.initFile(filedir, errfilename)
	// f.FileObj = fileObj
	// f.errfileObj = errfileObj
	err = f.initFile() // 调用initFile方法，打开2个文件，获得2个文件对象，构成一个完整的fileLogger实例
	if err != nil {
		panic(err)
	}
	return f

}

func (f *FileLogger) isEnable(lv LogLevel) bool {
	if lv >= f.level {
		return true
	} else {
		return false
	}
}

func (f *FileLogger) checkSize(fileObj *os.File) bool {
	// 获得传入文件的大小信息，并和f.maxsize比较
	fileInfo, err := fileObj.Stat()
	if err != nil {
		fmt.Printf("get file info failed,err : %v\n", err)
		return false
	}
	if fileInfo.Size() >= f.maxsize {
		return true
	} else {
		return false
	}
}

// splitFile 该函数，接收一个文件对象，然后获取当前时间戳，将接收的文件对象加一个时间戳后缀，然后关闭它，重命名它，然后再开一个和接收的文件对象同名的文件对象，并作为返回值返回
func (f *FileLogger) splitFile(file *os.File) (*os.File, error) {
	fileInfo, err := file.Stat()
	fileName := fileInfo.Name()
	nowSuffix := time.Now().Format("20060102150405000")
	// 关闭老的
	file.Close()
	// 重命名老的
	// os.Rename(fileName, fileName+"now")
	fullname := filepath.Join(f.filedir, fileName)
	os.Rename(fullname, fullname+nowSuffix)

	// 打开一个和老的文件，同名的，新文件
	newfileObj, err := os.OpenFile(fullname, os.O_CREATE|os.O_APPEND|os.O_WRONLY, 0644)
	if err != nil {
		fmt.Printf("open new file failed when split file, err:%v\n", err)
		return nil, err
	}
	return newfileObj, nil
}

// 改造：writeLogBackGround
func (f *FileLogger) writeLogBackGround() {

	// 放在goroutine中，利用无限循环从通道中取日志，再向文件中写日志
	for {
		if f.checkSize(f.fileObj) {

			newfileObj, err := f.splitFile(f.fileObj)
			if err != nil {
				fmt.Println(err)
			}
			f.fileObj = newfileObj

		}

		select {
		case alog := <-f.logmsg:
			// 从通道中取数据
			fmt.Fprintf(f.fileObj, "[%s] [%s] [%s:%s:%d] [%s]\n", alog.now, getLogString(alog.loglevel), alog.funName, alog.fileName, alog.lineNo, alog.msg)
			if alog.loglevel >= ERROR {
				if f.checkSize(f.errfileObj) {
					newfileObj, err := f.splitFile(f.errfileObj)
					if err != nil {
						fmt.Println(err)
					}
					f.errfileObj = newfileObj

				}
				fmt.Fprintf(f.errfileObj, "[%s] [%s] [%s:%s:%d] [%s]\n", alog.now, getLogString(alog.loglevel), alog.funName, alog.fileName, alog.lineNo, alog.msg)

			}
		default:
			// 若上面的分支不满足，即通道中没日志了，执行default分支，休息500毫秒
			time.Sleep(time.Microsecond * 500)
		}
	}

}

// recordLog ...
func (f *FileLogger) recordLog(lv LogLevel, format string, args ...interface{}) {
	// 将这个函数改成，负责构造日志消息的结构体实例，然后放到日志通道中
	// type logInfo struct {
	// 	now      string
	// 	loglevel LogLevel
	// 	funName  string
	// 	fileName string
	// 	lineNo   string
	// 	msg      string
	// 	// now, loglevel, funName, fileName, lineNo, msg
	// }
	if f.isEnable(lv) {
		msg := fmt.Sprintf(format, args...)
		time := time.Now().Format("2006-01-02 15:04:05.000")

		funName, fileName, lineNo := getCodeInfo(3) // 本层向外三层代码的信息

		alog := &logInfo{
			now:      time,
			loglevel: lv,
			funName:  funName,
			fileName: fileName,
			lineNo:   lineNo,
			msg:      msg,
		}

		select {
		case f.logmsg <- alog:
			// 写一条日志到通道
		default:
			// 正常应该走上面的分支，将日志消息放到通道中，若通道已满，走default分支 ，不做任何处理，丢掉该日志
		}
	}

	// // 接收三个参数，要打印的日志级别；格式化输出字符串，0或多个空接口类型的字符串（用一个空接口类型的切片接收）

	// // 先判断该级别日志是否打印，即该级别是否大于等于实例化时传入的日志级别

	// if f.isEnable(lv) {
	// 	// 如果大于等于，则记录，但记录前先判断当前日志文件是否需要切割

	// 	if f.checkSize(f.fileObj) {

	// 		newfileObj, err := f.splitFile(f.fileObj)
	// 		if err != nil {
	// 			fmt.Println(err)
	// 		}
	// 		f.fileObj = newfileObj

	// 	}
	// 	// 不需要切割，或切割后生成了新文件，继续下面的逻辑，记录日志

	// 	msg := fmt.Sprintf(format, args...)
	// 	now := time.Now().Format("2006-01-02 15:04:05.000")
	// 	// 日志级别
	// 	LevelStr := getLogString(lv)

	// 	// 调用记录日志的代码所在的行、函数名、文件名，利用runtime.Caller实现
	// 	funName, fileName, lineNo := getCodeInfo(3) // 本层向外三层代码的信息

	// 	fmt.Fprintf(f.fileObj, "[%s] [%s] [%s:%s:%d] [%s]\n", now, LevelStr, funName, fileName, lineNo, msg)

	// 	// 记录日志后，再判断下，当前日志级别是否大于等于ERROR，如果是，单独记录一条日志到errorlog文件中
	// 	if lv >= ERROR {
	// 		// 记录前，先判断errorlog文件的大小
	// 		if f.checkSize(f.errfileObj) {
	// 			newfileObj, err := f.splitFile(f.errfileObj)
	// 			if err != nil {
	// 				fmt.Println(err)
	// 			}
	// 			f.errfileObj = newfileObj

	// 		}
	// 		// 不需要切割，或切割后生成了新文件，继续下面的逻辑，记录错误日志

	// 		fmt.Fprintf(f.errfileObj, "[%s] [%s] [%s:%s:%d] [%s]\n", now, LevelStr, funName, fileName, lineNo, msg)

	// 	}

	// }
}

// DEBUG ...
func (f *FileLogger) DEBUG(format string, args ...interface{}) {

	f.recordLog(DEBUG, format, args...)
}

// TRACE ...
func (f *FileLogger) TRACE(format string, args ...interface{}) {
	f.recordLog(TRACE, format, args...)
}

// INFO ...
func (f *FileLogger) INFO(format string, args ...interface{}) {
	f.recordLog(INFO, format, args...)
}

// WARNING ...
func (f *FileLogger) WARNING(format string, args ...interface{}) {
	f.recordLog(WARNING, format, args...)
}

// ERROR ...
func (f *FileLogger) ERROR(format string, args ...interface{}) {
	f.recordLog(ERROR, format, args...)
}

// FATAL ...
func (f *FileLogger) FATAL(format string, args ...interface{}) {
	f.recordLog(FATAL, format, args...)
}

// initFile filelogger的方法，打开文件，获得文件对象，构成一个完整的filelogger对象
// 改进后，都是filelogger的方法了，（当然不需要再传递该结构体的字段值了，直接用
func (f *FileLogger) initFile() error {
	fullfilename := filepath.Join(f.filedir, f.filename)
	fileObj, err := os.OpenFile(fullfilename+".log", os.O_CREATE|os.O_APPEND|os.O_WRONLY, 0644)
	if err != nil {
		fmt.Printf("open file failed, err:%v\n", err)
		return err
	}
	f.fileObj = fileObj

	fullerrfilename := filepath.Join(f.filedir, f.errfilename)
	errfileObj, err := os.OpenFile(fullerrfilename+".log", os.O_CREATE|os.O_APPEND|os.O_WRONLY, 0644)
	if err != nil {
		fmt.Printf("open file failed, err:%v\n", err)
		return err
	}
	f.errfileObj = errfileObj
	go f.writeLogBackGround() // 实例化Fileloger时会调用initFile打开2个日志文件，顺便在这里，就开启后台写日志的函数，放在goroutine中执行，（等待从日志通道中取出一条条日志信息，写到日志文件中
	return nil
}

// func (f *FileLogger) initFile(filedir, filename string) (*os.File, error) {

// 	fullfilename := filepath.Join(filedir, filename)

// 	fileObj, err := os.OpenFile(fullfilename+".log", os.O_CREATE|os.O_APPEND|os.O_WRONLY, 0644)
// 	if err != nil {
// 		fmt.Printf("open file:%s failed, err:%v\n", filename, err)
// 		newerr := errors.New("open file failed")
// 		return nil, newerr
// 	}
// 	return fileObj, err
// }

```



